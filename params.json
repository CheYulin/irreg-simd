{"name":"Irreg-Simd","tagline":"Artifact of paper \"Exploiting Recent SIMD Architectural Advances for Irregular Applications\"","body":"# About\r\n\r\nThis code repository is used for your reference while you read our paper: Exploiting Recent SIMD Architectural Advances for Irregular Applications, which is published in 2016 International Symposium on Code Generation and Optimization (CGO 2016). \r\n\r\nThe codes listed here are the artifacts that have passed the Artifact Evaluation of CGO 2016. Please read EXECUTION_INSTRUCTION.pdf for the instructions on how to run our programs.\r\n\r\n# What our paper is about\r\n\r\nA broad class of applications involve indirect or datadependent\r\nmemory accesses and are referred to as irregular\r\napplications. Recent developments in SIMD architectures\r\n– specifically, the emergence of wider SIMD lanes,\r\ncombination of SIMD parallelism with many-core MIMD\r\nparallelism, and more flexible programming APIs – are providing\r\nnew opportunities as well as challenges for this class\r\nof applications. In this paper, we propose a general opti-\r\nmization methodology, to effectively optimize different subclasses\r\nof irregular applications. Based on the observation\r\nthat all applications with indirect memory accesses can be\r\nviewed as sparse matrix computations, we design an optimization\r\nmethodology, which includes three sub-steps: 1)\r\nlocality enhancement through tiling, 2) data access pattern\r\nidentification, and 3) write conflict removal at both SIMD\r\nand MIMD levels. This method has been applied to unstructured\r\ngrids, molecular dynamics, and graph applications,\r\nin addition to sparse matrix computations. The speedups\r\nachieved by our single threaded vectorized code over serial\r\ncode is up to 9.05, whereas the overall speedup while utilizing\r\nboth SIMD and MIMD (61 cores in Intel Xeon Phi)\r\nwith our approach is up to 467.1. Further optimization using\r\nmatrix reordering on irregular reductions and graph algorithms\r\nis able to achieve an incremental speedup of up to\r\n1.69, though at a relatively high preprocessing cost. Moreover,\r\nSpMM using our approach outperforms routines from\r\na highly optimized commercial library by up to 2.81x.\r\n\r\n# Contact\r\nIf you have any issues, please contact the author at lcchen008@gmail.com.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}